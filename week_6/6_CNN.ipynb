{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythonopdracht week 6: CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Loading-Images-from-Data-Set\" data-toc-modified-id=\"Loading-Images-from-Data-Set-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Loading Images from Data Set</a></span></li><li><span><a href=\"#Define-a-Convolutional-Neural-Network\" data-toc-modified-id=\"Define-a-Convolutional-Neural-Network-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Define a Convolutional Neural Network</a></span></li><li><span><a href=\"#Training-the-Network\" data-toc-modified-id=\"Training-the-Network-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Training the Network</a></span></li><li><span><a href=\"#Testing-the-Network\" data-toc-modified-id=\"Testing-the-Network-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Testing the Network</a></span></li><li><span><a href=\"#Improving-the-Network\" data-toc-modified-id=\"Improving-the-Network-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Improving the Network</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For this notebook, you will both answer questions and do some programming. Please write answes in green in the given Answer cells. Please write code where instructed.**\n",
    "\n",
    "This notebook is an adaptation of a demo notebook in the Pytorch documentation. Please be patient while running the code in the notebook. I haven't used any GPU that might be available on your computer. Training two epochs on my computer takes more than a minute (yes not too fast...).\n",
    "\n",
    "In order to run the code you need to install pytorch on your system. The modules `torch` and `torchvision` should be installed. See the [PyTorch](https://pytorch.org/) website how to install Pytorch on your machine.\n",
    "\n",
    "The [PyTorch](https://pytorch.org/) website is invaluable for understanding the code in this notebook. And it is a great source for further exploration of modern Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = None; \n",
    "# device = torch.device('cpu') # uncomment this line to explicitly set the device\n",
    "if device == None:\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA used\")\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        print(\"CPU used\")\n",
    "        device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Images from the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch has some well known data sets 'build in', among others the CIFAR data set. In the code below we download (if needed) and read in the data set. In the process of defining the train and test set PyTorch allows us to transform the images on the fly. In this case we only convert the image to a tensor (the basic PyTorch data structure comparable with the ndarray in numpy) and we normalize the image (by subtracting 0.5 from each rgb value in the image and dividing by 0.5, as each image has rgb values in the range from 0 to 1 we end up with values in the range from -1 to +1). Normalization of the data is important in any neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch loads a dataset into separate train and test sets. First we define the trainset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines if you get a SSL certificate error to disable the verification.\n",
    "# import ssl\n",
    "# ssl._create_default_https_context = ssl._create_unverified_context (edited) \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', \n",
    "                                        train=True, \n",
    "                                        download=True, \n",
    "                                        transform=transform)\n",
    "print(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainset has an attribute ``data`` that contains the entire datamatrix in a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. 50000 images of 32x32 pixels each with an R, G and B value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the labels are encoded in a simple Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainset.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target values are indices from 0 to 9 and the corresponding class names are encoded in the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = trainset.classes\n",
    "print(classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pure Python/Numpy we can now display one of the images with the target class name as title for the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 66\n",
    "plt.imshow(trainset.data[i])\n",
    "plt.axis('off')\n",
    "plt.title(classnames[trainset.targets[i]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on we will define a ``DataLoader`` that makes it easy to load a small number of (image, target) tuples (a batch) needed in one gradient descent step in the stochastic gradient learning process. While loading the data the data in the dataset is transformed on the fly. For this dataset two transforms are used in sequence. First the ``ToTensor`` transform that takes an HxWxC (with C=3) numpy array into a PyTorch tensor of shape CxHxW which is the standard for encoding color images in deep learning. The second transform in the sequence is a normalization (see the PyTorch documentation for ``torchvision.transforms.Normalize``)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 1.1**</span>.\n",
    "\n",
    "Given the normalization ``Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))`` and an original color value (r,g,b) what is the normalized color value (r',g',b')? What do all those values 0.5 represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Green\">\n",
    "    \n",
    "**Answer**\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way we define and load the testset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='./data', \n",
    "                                       train=False, \n",
    "                                       download=True, \n",
    "                                       transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define a DataLoader for both the train and testset. When defining a DataLoader we have to give the `batch_size` as argument for the class constructor. A DataLoader, being a Python iterable, makes it possible to retrieve batch_size arbitrary images from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, \n",
    "                                         batch_size=batch_size, \n",
    "                                         shuffle=False, \n",
    "                                         num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Tensor Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For displaying 'tensor images' we provide two helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, ax=None):\n",
    "    \"\"\"imshow for Tensor Images obtained with a DataLoader\n",
    "    from a data set. The images are of shape (3,M,N)\n",
    "    and are in the range from -1 to +1\"\"\"\n",
    "    img = (img - img.min()) / (img.max()-img.min())     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if ax==None:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    else:\n",
    "        ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "def imtable(imgs, titles, ncols, hsize=4, vsize=4):\n",
    "    nrows = int(np.ceil(len(imgs)/ncols))\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=(ncols*hsize, nrows*vsize))\n",
    "    r, c = 0, 0\n",
    "    for i, (im, label) in enumerate(zip(imgs, titles)):\n",
    "        if nrows==1:\n",
    "            ax = axs[c]\n",
    "        elif ncols==1:\n",
    "            ax = axs[r]\n",
    "        else:\n",
    "            ax = axs[r,c]\n",
    "        imshow(im, ax=ax)\n",
    "        ax.set_title(titles[i])\n",
    "        ax.axis('off')\n",
    "        c += 1\n",
    "        if c == ncols:\n",
    "            r += 1\n",
    "            c = 0\n",
    "    plt.tight_layout()\n",
    "        \n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "imtable(images, [classnames[i] for i in labels], 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 1.2**</span>.\n",
    "\n",
    "If you would be random guessing the class of an image what would be the expected accuracy of the 'classifier'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Green\">\n",
    "    \n",
    "**Answer**\n",
    "    \n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following CNN to classify the CIFAR images. Observe that first the functional processing blocks in the CNN are instantiated in the ``__init__`` function and then used in the ``forward`` method implementing the forward pass from input to output of the network.\n",
    "\n",
    "The backpropagation pass to calculate the derivatives of the loss with respect to the data throughout the network is automagically done by PyTorch. Only when you as a programmer introduce new functional processing blocks you have to implement the backward pass yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Note in the forward pass we have 'numbered'\n",
    "        # the x's just to make it easier to collect\n",
    "        # the code to print information about the network\n",
    "        # further on in the code.\n",
    "        x1a = self.conv1(x)\n",
    "        x1 = self.pool1(F.relu(x1a))\n",
    "        x2 = self.pool2(F.relu(self.conv2(x1)))\n",
    "        x3 = torch.flatten(x2, 1) # flatten all dimensions except batch\n",
    "        x4 = F.relu(self.fc1(x3))\n",
    "        x5 = F.relu(self.fc2(x4))\n",
    "        x6 = self.fc3(x5)\n",
    "            \n",
    "        if self.verbose:\n",
    "            # Write the code to print the properties of the \n",
    "            # different stages in the CNN\n",
    "            # Your code here\n",
    "            self.verbose -= 1\n",
    "        \n",
    "        return x6\n",
    "\n",
    "# with verbose=1 the 'debugging' code is printed only once \n",
    "# while running the forward pass multiple times.\n",
    "net = Net(verbose=1).to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the class definition for a network we can print an instantiation of that class to obtain an overview of the functional processing blocks that are defined. Note that the ``relu`` and ``flatten`` functions are not printed (but they are in the flow of processing blocks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the shapes of the data that is processed at all layers in the network is not printed. That is where we need 'your code' in the ``Net`` class.\n",
    "\n",
    "The code below sets the verbose attribute of the ``Net`` instantiation to 1 and then feeds it a batch of images. The output is printed, which is not needed of course as it will be total nonsense as nothing is learned yet.\n",
    "\n",
    "It should be noted that PyTorch automagically takes care of proper initialization of the parameters of each of the processing modules in the network. If you want to you can override the default initialization (read the docs for that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.verbose=1 # when you run it you should set this to 1\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "outputs = net(images)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the printed information you ought to be able to answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a data graph the first part of this network looks like\n",
    "<img src=\"https://rvdboomgaard.github.io/ComputerVision_LectureNotes/_static/cifar_cnn_incomplete.png\"\n",
    "     width=80%\n",
    "     alt=\"data flow graph\"\n",
    "     style=\"float: center;\" />\n",
    "\n",
    "The CIFAR images are 32x32 color images, so $W_1 = H_1 = 32$ and $C_1 = 3$. \n",
    "\n",
    "Observe that in this common way to depict a CNN the blocks that are drawn corresponds with the data, the arrows correspond with the data processing modules. E.g. the first arrow corresponds with the sequence Conv1 --> ReLU --> Maxpool modules. \n",
    "\n",
    "The last data block in this CNN is a vector of 10 elements where each element equals the activation for one of the 10 classes. This last layer is obtained with a fully connected neural network from the layer before that which is also a vector but with 84 elements.\n",
    "\n",
    "Note that if you want to know what the data shape is after just the first or second convolution you have to change the code in the ``forward`` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2.1**</span>\n",
    "\n",
    "If you print the shape of tensor ``x`` in the ``forward`` method you will get ``torch.Size([4, 3, 32, 32])``. Why is the first dimension of size 4 in this tensor? Note that this size is NOT depicted in the above graph!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Green\">\n",
    "    \n",
    "**Answer**\n",
    "    \n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2.2**</span>\n",
    "\n",
    "What is the shape of the tensor that results from ``conv1(x)``? What does it tell you about the convolution/correlation algorithm that is used? To find this experimentally you have to change the code in the ``forward`` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Green\">\n",
    "    \n",
    "**Answer**\n",
    "    \n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2.3**</span>\n",
    "\n",
    "Complete the data graph. For each of data block (image blocks at the start and flattened arrays at the end) you should indicate the shape of the block. The blocks correspond with the tensors `x`, `x1` ... `x6` in the `forward` method. Either you should look into the documentation of the processing modules that are being used in the `__init__` function or you should run the code and print the shapes (when we are running/training the network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Green\">\n",
    "    \n",
    "**Answer**\n",
    "    \n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2.4**</span>\n",
    "\n",
    "In the `__init__` function the following processing modules are defined: `conv1`, `pool1`, `conv2`, `pool2`, `fc1`, `fc2` and `fc3`. Indicate where these modules are used in your data flow graph (i.e. you have to label the arrows in the graph with the (sequence of) operations associated with each arrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Green\">\n",
    "    \n",
    "**Answer**\n",
    "    \n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2.5**</span>\n",
    "\n",
    "For each of processing modules `conv1`, `pool1`, `conv2`, `pool2`, `fc1`, `fc2` and `fc3` give the number of parameters that have to be learned (don't forget the bias parameters...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Green\">\n",
    "    \n",
    "**Answer**\n",
    "    \n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HINT**: The answer to question 2.5 can be computed by 'interrogating' the network. For instance for the `fc2` linear module we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer to the last question from the above cell can be computed by 'interrogating' the network. For instance for the `fc2` linear module we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in net.fc2.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for this module there are two tensors defining the parameters. Note that an object of type `torch.Size` is not a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2.6**</span>\n",
    "\n",
    "What are these tensors? (please look back in your machine learning course notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Green\">\n",
    "    \n",
    "**Answer**\n",
    "    \n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2.7**</span>\n",
    "\n",
    "How many parameters in total for this `fc2` module?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Green\">\n",
    "    \n",
    "**Answer**\n",
    "    \n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you have to write the code to calculate the total number of parameters to be learned in this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to calculate the total number of parameters in the entire network\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on in this notebook we revisit the interrogation of the network again to actually observe what parameter values are learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the network we also need to define a loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the network is fed input the output is obtained with ``outputs = net(inputs)``, then the outputs are compared with the target values (labels in our case) with the `CrossEntropyLoss` function. Read the PyTorch documentation to learn why this loss is well suited for a classification problem (and why the softmax function is not needed in this network).\n",
    "\n",
    "Observe that although the output of the network is a 10 element vector (activation for each of the different classes) the target value is an integer id for the target class. The conversion to one-hot-encoding is implicitly done within the loss function (see the source code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need an optimizer. A standard optimizer is PyTorch is the SGD (Stochastic Gradient Descent) optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, dampening=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here `lr` is the learning rate. The momentum is used in the gradient descent procedure to 'remember' in which direction the gradient descent is running and not deviate too easily from that direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 2.8**</span>\n",
    "\n",
    "Read the explanation of the SGD optimizer in the PyTorch documentation.\n",
    "1. Why the name **stochastic** gradient descent?\n",
    "2. What value for the ``momemtum`` and `dampening` should be chosen to get the classical gradient descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Green\">\n",
    "    \n",
    "**Answer**\n",
    "    \n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the network using a variant of the gradient descent algorithm boils down to:\n",
    "1. feed a minibatch of examples to the network\n",
    "2. run the forward pass, i.e. calculate the output through all its intermediate processing modules)\n",
    "3. set all gradients (derivative of the loss with respect to all parameters) equal to zero\n",
    "4. calculate the backward pass (to calculate all gradients\n",
    "5. for each of the parameters make a step in the right direction and adapt the parameters accordingly.\n",
    "\n",
    "This process is repeated until the minibatches have fed all examples in the training set to the learning algorithm. That completex one **epoch** in learning. Then this process is repeated until a specified number of epochs is done.\n",
    "\n",
    "In the learning process we keep track of the loss on the learning set and the loss on the test set both of which are calculated after each epoch. To have some indication whether the network is learning during an epoch we also report the loss over the last batches fed to the netword for learning.\n",
    "\n",
    "One epoch of learning is encaptured in the `train_loop` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, no_report=1000, device=None):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Move the data to GPU (if available)\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % no_report == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While learning for several epochs we also calculate the performance on the test or validation set. This is encoded in the function `test_loop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, device=None):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning process then becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, net, loss_criterion, optimizer, device=device)\n",
    "    test_loop(testloader, net, loss_criterion, device=device)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following 2 lines to save your network to file\n",
    "#PATH = './cifar_net_100e.pth'\n",
    "#torch.save(net.state_dict(), PATH)\n",
    "#\n",
    "# when saved you can load it back into memory with\n",
    "# (again uncomment the following 2 lines)\n",
    "#net = Net().to(device)\n",
    "#net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load some images from the test set, display these image with their ground truth label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "imtable(images, [classnames[i] for i in labels], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run these image through the network and print the outputs of the 10 output nodes for all images. Note that now we are not training the network Pytorch doesn't need to keep track of all the intermediate outputs of all modules in the network (in preparation of a backward pass) and we can tell Pytorch not to do that with `no_grad()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While learning we didn't use the `softmax` function (see the PyTorch documentation) that normalizes the output for the 10 classes such that the a posteriori class probability if modeled (that would not be what the loss function expects). Now we are using the network in the feed forward mode only we will apply the softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = F.softmax(net(images.to(device)), dim=-1)\n",
    "npoutputs = outputs.cpu().numpy()\n",
    "print(npoutputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted label will be the label with the largest output value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxvalue, maxindex = torch.max(outputs, 1)\n",
    "print('True     : ', ' '.join('%10s' % classnames[labels[j]]\n",
    "                              for j in range(batch_size)))\n",
    "print('Predicted: ', ' '.join('%10s' % classnames[maxindex[j]]\n",
    "                              for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For such a small set of test images we run into the possibility that the classification is very bad. Let's test the network more carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general it is really hard to understand what a (convolutional) neural network is doing. What do the learned weights represent? The answer to that question is still largely unknown. There are several papers that describe what particular nodes in the network are responsive to. These methods are beyond the scope of a bachelor course.\n",
    "\n",
    "An exception is the first layer in a CNN. The convolutions there directly operate on the (color) image data and like we are used to in computer vision the convolution kernels (weigh functions) can be visualized as images themselves.\n",
    "\n",
    "The hypothesis in developing CNN's was that local structure in images carries the spatial information needed to interpret the images. So when visualizing the kernels from the first convolution layer we hope to see the network has learned to respond to all sorts of local structure patterns.\n",
    "\n",
    "These patterns are then in layers downwards in the datastream combined to recognize larger structures in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to visualize the kernels in the first convolution module `conv1` as small images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the code to visualize the kernels\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a network architecture for a CNN is more of an art than a science. Simple experimenting with different number of channels, with different number of (convolution) layers can sometimes improve your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Question 5.1**</span>\n",
    "\n",
    "1. The obvious way to start improving your network is by training for more epochs. Only 2 epochs is really not much (but you need a fast computer or a GPU or a lot of patience). But you should be able to increase the number of epochs from 2 to 10 when you run the learning at night.\n",
    "\n",
    "1. Change the number of channels in the first data (image) block after the input image (a block with 3 channels) from 10 to 20 and train and run the network again. Does it improve the performance? Again start with 2 epochs of learning.\n",
    "\n",
    "1. Change the size of the convolution kernels in the `conv1` module from 5 to 3. Again start with 2 epochs of learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:Green\">\n",
    "    \n",
    "**Answer**\n",
    "    \n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The speed of learning can be dramaticall improved by moving the entire dataset to the gpu (in case you have enough RAM on the gpu). I had a hard time to achieve that. If you can find an elegant way without the need to rewrite the data loaders i would be very interested.\n",
    "\n",
    "- When you can learn faster or have a faster machine or have more time you could learn for a lot of epochs (say 100) and then plot the loss and accuracy for both the train and test set as a function of the number of epochs. That may provide you with evidence that the network is overfitting and thus that some regularization techniques might be neededn. This is suggested by the webpages describing learning for the same dataset but then implemented in Keras/Tensorflow (see https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/). There the loss and accuracy as function of the number of epochs is shown as (in yellow the testset scores and in blue the trainset scores):\n",
    "<img src=\"https://rvdboomgaard.github.io/ComputerVision_LectureNotes/_static/cifar_overfitting.png\"\n",
    "     width=50%\n",
    "     alt=\"data flow graph\"\n",
    "     style=\"float: center;\" />\n",
    "The network used was very much like the one that has been used in this lab.\n",
    "\n",
    "- In the above mentioned paper using Keras/Tensorflow the problem over overfitting was succesfully mitigated using DropOut's in the network. It would be nice to see if you can do the same for our network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
